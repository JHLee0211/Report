### multi-variable linear regression

---

#### 복습

```
 Hypothesis : H(x) = Wx + b (W=weight, b=bias) >> 두 개의 값 학습
 
 Cost function
 	cost(=loss) 를 구하는 법
 	Cost(W,b) = 1/(m) * (i=1→m) ∑ (H(x(i)) - y(i))^2
 
 Gradient descent algorithm : 경사면을 따라 내려가면서 최적한 값을 찾는 것
```

​	위 수식들은 하나의 variable을 가지고 결과를 도출하지만, multi-variable 은 어떻게 할까?

#####   Hypothesis

​	H(x) = Wx + b
​	H(x1, x2, x3) = w1x1 + w2x2 + w3x3 + b

#####   Cost function 

​	H(x1, x2, x3) = w1x1 + w2x2 + w3x3 + b
​	cost(W,b) = 1/(m) * (i=1→m) ∑ (H(x1(i),x2(i),x3(i)) - y(i))^2

##### 	ㄴ 하지만, 위의 방법은 수가 많아질 수록 식이 복잡해지고 불편함.... >>> 따라서 Matrix 이용!



#### Matrix multiplication

- ##### 함수의 곱을 이용하여 Hypothesis 표현

  ```
  			   ( w1 )
  ( x1 x2 x3 ) * ( w2 ) = ( x1w1 + x2w2 + x3w3 )
  			   ( w3 )
  ```

- ##### H(X) = XW

  ```
  variable이 한 개일 때는 H(x) = Wx + b이지만, 
  matrix 사용 시에는 H(X) = XW 로 X를 먼저 두고 계산해주면 
  tensorflow에서 별도의 처리 없이 바로 계산 가능
  ```

  

#### Multi-variable linear regression 구현하기


* 코드 (C:\Users\cjstn\AppData\Local\Programs\Python\Python36 안의 tensorPrac4.py)
* 코드 (C:\Users\cjstn\AppData\Local\Programs\Python\Python36 안의 tensorPrac5.py)

##### Loading data from file 구현하기

https://www.youtube.com/watch?v=o2q4QNnoShY


 ▶ Slicing

	nums = range(5)		# range is a built-in function that creates a list of integers
	print nums		# Prints "[0, 1, 2, 3, 4]"
	print nums[2:4]		# Get a slice from index 2 to 4 (exclusive); prints "[2, 3]"
	print nums[2:]		# Get a slice from index 2 to the end; prints "[2, 3, 4]"
	print nums[:2]		# Get a slice from the start to index 2 (exclusive); prints "[0,1]"
	print nums[:]		# Get a slice from the whole list; prints ["0, 1, 2, 3, 4]"
	print nums[:-1]		# Slice indices can be negative; prints ["0, 1, 2, 3]"		# -1 = end, prints all exclusive end
	print num[-1]		# Prints only end of the array "[4]"
	nums[2:4] = [8,9]	# Assign a new sublist to a slice
	print nums		# prints "[0, 1, 8, 9, 4]"


 ▶ 2차원 Slicing

	- Array또한 indexed, sliced, iterated 가능(list와 같이)
	- list와 같이, 콜론(:) syntax를 통해 슬라이싱 가능
	- 콜론(:)은 dots(...)로 대체 가능


	arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])
	# arr ([[ 1,  2,  3,  4],
	#	[ 5,  6,  7,  8],
	#	[ 9, 10, 11, 12]])
	
	arr[:, 1]			# , 기준으로 앞은 row, 뒤는 col
	# arr ([ 2, 6, 10])
	
	arr[-1]
	# arr ([ 9, 10, 11, 12])
	
	arr[-1, :]
	# arr ([ 9, 10, 11, 12])
	
	arr[-1, ...]
	# arr ([ 9, 10, 11, 12])
	
	arr[0:2, :]
	# arr ([[1, 2, 3, 4],
	#	[5, 6, 7, 8]])


 ▶ 파일 불러오기


 * data-01-test-score.csv

```	
  #EXAM1,EXAM2,EXAM3,FINAL
  73,80,75,152
  93,88,93,185
  89,91,90,180
  96,98,100,196
  73,66,70,142
  53,46,55,101
```


 * 코드

```python
import numpy as np
import tensorflow as tf

xy = np.loadtxt('data-01-test-score.csv', delimiter=',', dtype = np.float32)

x_data = xy[:, 0:-1]		# row는 전부, col은 0에서 (end를 제외한) 전부
y_data = xy[:, [-1]]		# row는 전부, col은 end만


# Make sure the shape and data are OK (불러온 데이터 확인)

print(x_data.shape, x_data, len(x_data))
print(y_data.shape, y_data)
```



### Logistic Classification

---

- ##### Regression은 숫자 예측이었다면, Classification 은 Binary 중 결정하는 것

  - Pass / Fail, True / False, Up / Down, Show / Hide 등을 예측

  ```
   g(x) = 1/(1+e^(-x))
  ```

  ​		>> x가 작아질수록 g(x)는 0에 가까워지고, x가 커질수록 g(x)는 1에 가까워짐

#####   sigmoid	

      H(X) = 1 / (1+e^(-W^T * X))
      cost(W) = 1/m ∑ c(H(x),y)
      c(H(x),y) = -log(H(x))    : y = 1
    		    = -log(1-H(x))  : y = 0
    
      c(H(x),y) = -ylog(H(x)) - (1-y)log(1-H(x))



## 알고리즘 (프로그래머스)

### Greedy

 - ##### 42862. 체육복

```java
import java.util.*;

public class Solution_prog_42862_체육복 {
	public static void main(String[] args) {
		int[] lost = new int[] {2,4};
		int[] reserve = new int[] {1,3,5};
		System.out.println(solution(5,lost, reserve));
	}
	   public static int solution(int n, int[] lost, int[] reserve) {
	        int answer = 0;
	        int[] clothes = new int[n];
	        Arrays.fill(clothes, 1);
	        for(int i=0; i<lost.length; i++){
	            clothes[lost[i]-1]--;
	        }
	        for(int i=0; i<reserve.length; i++){
	            clothes[reserve[i]-1]++;
	        }
	        for(int i=0; i<n; i++){
	            if(clothes[i]==0){
	                if(i==0){
	                    if(clothes[i+1]==2) {clothes[i]++; clothes[i+1]--;}
	                }else if(i==n-1){
	                    if(clothes[i-1]==2) {clothes[i]++; clothes[i-1]--;}
	                }else{
	                    if(clothes[i-1]==2) {clothes[i]++; clothes[i-1]--; continue;}
	                    else if(clothes[i+1]==2) {clothes[i]++; clothes[i+1]--;}
	                }
	            }
	        }
	        for(int i=0; i<n; i++){
	            if(clothes[i]>0) answer++;
	        }
	        return answer;
	    }
}
```



- ##### 42883. 큰수만들기

```java
public class Solution_prog_42883_큰수만들기 {
	public static void main(String[] args) {
		String number = "4177252841";
		int k = 4;
		System.out.println(solution(number, k));
	}
    public static String solution(String number, int k) {
        String answer = "";
        int n = number.length()-k, i=0, ind=0, tempk=k;
  ret:      while(answer.length()!=n){
            int max=0;
            for(; i<tempk+1; i++){
                if(number.charAt(i)-'0'>max){
                    if(k+answer.length()==i){
                        answer+=(number.substring(i,number.length()));
                        break ret;
                    }
                    max=number.charAt(i)-'0';
                    ind=i;
                }
            }
            tempk++;
            if(tempk+1>number.length()) tempk=number.length()-1;
            answer+=max;
            i=ind+1;
        }
        return answer;
    }
}
```